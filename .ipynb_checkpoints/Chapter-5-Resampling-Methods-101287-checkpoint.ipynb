{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9206224-0ccc-439c-a636-79cf6202d607",
   "metadata": {},
   "source": [
    "# 5.3 Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8a4a72-68bd-4e5e-908e-c878d8fcfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We again begin by placing most of our imports at this top level.\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                        summarize ,\n",
    "                        poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332639ec-4c11-40fd-9fb5-b08a4b7d936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several new imports needed for this lab.\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate ,\n",
    "      KFold ,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e650a6-cfb4-41e0-bd53-1b03348d13c3",
   "metadata": {},
   "source": [
    "### 5.3.1 The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d9e66a-754f-4c5e-b968-3f406d98b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the random seed of the splitter with the argument random_state=0.\n",
    "Auto = load_data('Auto')\n",
    "Auto_train , Auto_valid = train_test_split(Auto ,\n",
    "                                          test_size=196,\n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2caa8af-2ac0-4b97-bc5d-8012cff83244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit a linear regression using only the observations corresponding to the training set Auto_train.\n",
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train , X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa526efd-efad-4574-9951-87b06e9e494f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now use the predict() method of results evaluated on the model matrix for this model created using the validation data set. We also calculate the validation MSE of our model.\n",
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b9c83fa-82f3-431b-bb72-59c10dfef296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also estimate the validation error for higher-degree polynomial\n",
    "#regressions. We first provide a function evalMSE() that takes a model string\n",
    "#as well as a training and test set and returns the MSE on the test set.\n",
    "\n",
    "def evalMSE(terms ,\n",
    "            response ,\n",
    "            train ,\n",
    "            test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "    results = sm.OLS(y_train , X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    \n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4203960b-8e69-4fe1-a115-95ed74fc7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the enumerate() function here, which gives both the values and indices of objects as one iterates over a for loop.\n",
    "MSE = np.zeros(3)\n",
    "for idx , degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train ,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e06b9b79-2bcf-4bac-a9c4-64a7b13bab1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we choose a different training/validation split instead, then we can expect somewhat different errors on the validation set.\n",
    "Auto_train , Auto_valid = train_test_split(Auto ,\n",
    "                                           test_size=196,\n",
    "                                           random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx , degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train ,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af769bf-c974-44a9-901c-7e274b75b74e",
   "metadata": {},
   "source": [
    "### 5.3.2 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72cbcec5-9c1b-48d2-8c50-f7559534bec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.23151351792922"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is passed as model_args={'family':sm.families.Binomial()}.\n",
    "hp_model = sklearn_sm(sm.OLS ,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model ,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84fbf1e7-6e67-412b-869c-7b705dbae854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        , 19.03322528])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To automate the process, we again use a for loop which iteratively fits\n",
    "#polynomial regressions of degree 1 to 5, computes the associated crossvalidation\n",
    "#error, and stores it in the ith element of the vector cv_error.\n",
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4457797-e89c-4dd4-a79e-bcea44002e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It has two arrays as arguments, and then forms a larger array where the operation is applied to each pair of elements of the two arrays.\n",
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13c79dd6-29bc-45c1-b5d6-3d98c2f9cbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848402, 19.13719048])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use random_state to set a random seed and initialize a vector cv_error in KFold()\n",
    "#which we will store the CV errors corresponding to the polynomial fits of\n",
    "#degrees one to five.\n",
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True ,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a90f140d-196e-4098-bc76-9675b191201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The cross_validate() function is flexible and can take different splitting mechanisms as an argument.\n",
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model ,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cd690e0-492d-471c-842f-f028913f51f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.802232661034164, 1.4218450941091831)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One can estimate the variability in the test error by running the following:\n",
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model ,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040a24c-6c54-46d7-a3a5-0c876af95247",
   "metadata": {},
   "source": [
    "### 5.3.3 The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b357830-7c59-4138-90b5-a57a9bf24c9a",
   "metadata": {},
   "source": [
    "#### Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc0a352a-6e3c-4e4d-b131-4774ca80ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function then outputs the estimate for ) based on the selected observations.\n",
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1,1] - cov_[0,1]) /\n",
    "            (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "358dc419-4cc9-40c7-9dd3-a1eabd42720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following command estimates ) using all 100 observations\n",
    "alpha_func(Portfolio , range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3900b168-d0b5-43d9-8b5b-9832d9c3e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619004"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is equivalent to constructing a new bootstrap data set and recomputing ˆ) based on the new data set.\n",
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio ,\n",
    "           rng.choice(100,\n",
    "                      100,\n",
    "                      replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c05a8cb2-2133-46a0-806a-e798f2539c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process can be generalized to create a simple function boot_SE() for\n",
    "#computing the bootstrap standard error for arbitrary functions that take only a data frame as an argument.\n",
    "def boot_SE(func ,\n",
    "            D,\n",
    "            n=None ,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_ , second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index ,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6fb24a0-0d19-40b2-a38b-e99ed5d48909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277699"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s use our function to evaluate the accuracy of our estimate of ) using B = 1,000 bootstrap replications\n",
    "alpha_SE = boot_SE(alpha_func ,\n",
    "                   Portfolio ,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a9f41-850e-4e20-8be1-794225c72253",
   "metadata": {},
   "source": [
    "#### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28635138-93bf-4268-9721-d92d6ace0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This means that any derived features such clone() as those defined by poly() (which we will see shortly), will be re-fit on the resampled data frame.\n",
    "def boot_OLS(model_matrix , response , D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "accfee1b-7b65-47da-8416-57619e012bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use it to freeze the first two model-formula arguments of boot_OLS().\n",
    "from functools import partial\n",
    "from ISLP.models import ModelSpec as MS\n",
    "\n",
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "788d095c-12b9-492a-bbc4-eb7ab33f1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first demonstrate its utility on 10 bootstrap samples.\n",
    "#rng = np.random.default_rng(0)\n",
    "#np.array([hp_func(Auto ,\n",
    "#                  rng.choice(392,\n",
    "#                             392,\n",
    "#                             replace=True)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3cee345-0f53-488e-84b8-b5a72404b057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.731176\n",
       "horsepower    0.006092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we use the boot_SE() function to compute the standard errors of 1,000 bootstrap estimates for the intercept and slope terms.\n",
    "hp_se = boot_SE(hp_func ,\n",
    "                Auto ,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e7336c2-7e15-4166-bb7f-749674cf04c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These can be obtained using the summarize() function from ISLP.sm.\n",
    "hp_model.fit(Auto , Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "22ae341d-c654-42c7-82ed-fb8bd531afac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.538641\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.024696\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below we compute the bootstrap standard error estimates and the standard linear regression estimates that result from fitting the quadratic model to the data.\n",
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS ,\n",
    "                    quad_model ,\n",
    "                    'mpg')\n",
    "boot_SE(quad_func , Auto , B=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f3cf266-e925-4d53-b016-8adafdc1dadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We compare the results to the standard errors computed using sm.OLS().\n",
    "M = sm.OLS(Auto['mpg'],\n",
    "           quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb4f6e-9f14-4494-aa7a-7c85016c0a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
